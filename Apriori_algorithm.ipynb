{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c14b63",
   "metadata": {},
   "source": [
    "## Apriori Algorithm\n",
    "minsup: 0.3\n",
    "minconf: 0.8\n",
    "minlift: 1.0\n",
    "filename: 'supermarket.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd82e2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Freq            Conseq  Lift  Confidence  Support\n",
      "0                 (total = high)  (bread and cake)  1.17        0.84     0.31\n",
      "1                    (margarine)  (bread and cake)  1.11        0.80     0.40\n",
      "2              (fruit, biscuits)  (bread and cake)  1.17        0.84     0.33\n",
      "3         (vegetables, biscuits)  (bread and cake)  1.17        0.84     0.32\n",
      "4         (biscuits, milk-cream)  (bread and cake)  1.17        0.84     0.32\n",
      "5       (biscuits, frozen foods)  (bread and cake)  1.16        0.83     0.33\n",
      "6          (fruit, frozen foods)  (bread and cake)  1.16        0.83     0.33\n",
      "7            (fruit, milk-cream)  (bread and cake)  1.15        0.83     0.36\n",
      "8     (baking needs, milk-cream)  (bread and cake)  1.15        0.83     0.34\n",
      "9     (frozen foods, milk-cream)  (bread and cake)  1.15        0.83     0.33\n",
      "10      (baking needs, biscuits)  (bread and cake)  1.15        0.83     0.31\n",
      "11      (vegetables, milk-cream)  (bread and cake)  1.14        0.82     0.36\n",
      "12         (baking needs, fruit)  (bread and cake)  1.14        0.82     0.34\n",
      "13    (vegetables, frozen foods)  (bread and cake)  1.14        0.82     0.33\n",
      "14           (vegetables, fruit)  (bread and cake)  1.13        0.81     0.39\n",
      "15    (baking needs, vegetables)  (bread and cake)  1.13        0.81     0.34\n",
      "16  (baking needs, frozen foods)  (bread and cake)  1.12        0.81     0.32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def load_data_set(filename):\n",
    "    # Importing dataset\n",
    "    data = pd.read_csv(filename, header = None)\n",
    "    df_shape = data.shape\n",
    "    n_of_transactions = df_shape[0]\n",
    "    n_of_products = df_shape[1]\n",
    "\n",
    "    # Converting dataframe into a list of lists for Apriori algorithm\n",
    "    records = []\n",
    "    for i in range(0, n_of_transactions):\n",
    "        records.append([])\n",
    "        for j in range(0, n_of_products):\n",
    "            if (str(data.values[i,j]) != 'nan'):\n",
    "                records[i].append(str(data.values[i,j]))\n",
    "            else:\n",
    "                continue\n",
    "    return records\n",
    " \n",
    "def Create_C1(data_set):\n",
    "    # Creating frozenset for each item\n",
    "    C1 = set()\n",
    "    for t in data_set:\n",
    "        for item in t:\n",
    "            item_set = frozenset([item])\n",
    "            C1.add(item_set)\n",
    "    return C1\n",
    " \n",
    "def is_apriori(Ck_item, Lk_sub_1):\n",
    "    for item in Ck_item:\n",
    "        sub_item = Ck_item - frozenset([item])\n",
    "        if sub_item not in Lk_sub_1:\n",
    "            return False\n",
    "    return True\n",
    " \n",
    "def Create_Ck(Lk_sub_1, k):\n",
    "    Ck = set()\n",
    "    len_Lk_sub_1 = len(Lk_sub_1)\n",
    "    list_Lk_sub_1 = list(Lk_sub_1)\n",
    "    for i in range(len_Lk_sub_1): #i: [0, len_Lk_sub_1)\n",
    "        for j in range(i+1, len_Lk_sub_1): #j: [i+1, len_Lk_sub_1)\n",
    "            l1 = list(list_Lk_sub_1[i])\n",
    "            l2 = list(list_Lk_sub_1[j])\n",
    "            l1.sort()\n",
    "            l2.sort()\n",
    "            if l1[0:k-2] == l2[0:k-2]:\n",
    "                Ck_item = list_Lk_sub_1[i] | list_Lk_sub_1[j]\n",
    "                if is_apriori(Ck_item, Lk_sub_1):\n",
    "                    Ck.add(Ck_item)\n",
    "    return Ck\n",
    " \n",
    "def Generate_Lk_By_Ck(data_set, Ck, minsup, support_data):\n",
    "    Lk = set()\n",
    "    item_count = {}\n",
    "    for t in data_set:\n",
    "        for Ck_item in Ck:\n",
    "            if Ck_item.issubset(t):\n",
    "                if Ck_item not in item_count:\n",
    "                    item_count[Ck_item] = 1\n",
    "                else:\n",
    "                    item_count[Ck_item] += 1\n",
    "    data_num = float(len(data_set))\n",
    "    for item in item_count:\n",
    "        if(item_count[item] / data_num) >= minsup:\n",
    "            Lk.add(item)\n",
    "            support_data[item] = item_count[item] / data_num\n",
    "    return Lk\n",
    "\n",
    "def Generate_L(data_set, minsup, max_k = 10):\n",
    "    # Creating a dict that has the frequent itemset as key and corresponding support as value\n",
    "    support_data = {}\n",
    "    C1 = Create_C1(data_set)\n",
    "    L1 = Generate_Lk_By_Ck(data_set, C1, minsup, support_data)\n",
    "    Lk_sub_1 = L1.copy()\n",
    "    L = []\n",
    "    L.append(Lk_sub_1)\n",
    "    for k in range(2, max_k+1):\n",
    "        Ck = Create_Ck(Lk_sub_1, k)\n",
    "        Lk = Generate_Lk_By_Ck(data_set, Ck, minsup, support_data)\n",
    "        Lk_sub_1 = Lk.copy()\n",
    "        L.append(Lk_sub_1)\n",
    "    return L, support_data\n",
    " \n",
    "def Generate_Rule(L, support_data, minconf, minlift):\n",
    "    rule_list = []\n",
    "    sub_set_list = []\n",
    "    for i in range(len(L)):\n",
    "        for frequent_set in L[i]:\n",
    "            for sub_set in sub_set_list:\n",
    "                if sub_set.issubset(frequent_set):\n",
    "                    # Calculating lift, conf, support\n",
    "                    support = support_data[frequent_set]\n",
    "                    conf = support_data[frequent_set] / support_data[sub_set]\n",
    "                    lift = conf / support_data[frequent_set-sub_set]\n",
    "                    rule = [sub_set, frequent_set-sub_set, round(lift, 2), round(conf, 2), round(support, 2)]\n",
    "                    if minlift == 'NULL':\n",
    "                        if conf >= minconf and rule not in rule_list:\n",
    "                            rule_list.append(rule)\n",
    "                    else:\n",
    "                        if conf >= minconf and rule not in rule_list and lift >= minlift:\n",
    "                            rule_list.append(rule)\n",
    "            sub_set_list.append(frequent_set)\n",
    "    return rule_list\n",
    "   \n",
    "def main(minsup, minconf, minlift, filename):\n",
    "    data_set = load_data_set(filename)\n",
    "    L, support_data = Generate_L(data_set, minsup)\n",
    "    rule_list = Generate_Rule(L, support_data, minconf, minlift)\n",
    "    \n",
    "    df = pd.DataFrame(rule_list)\n",
    "    df.columns = ['Freq', 'Conseq', 'Lift', 'Confidence', 'Support']\n",
    "    df['Num_items'] = df.apply(lambda row: len(row.Freq) + len(row.Conseq), axis=1)\n",
    "\n",
    "    sorted_df = df.sort_values(['Num_items', 'Lift', 'Confidence', 'Support'], \n",
    "                          ascending = [True, False, False, False])\n",
    "    sorted_df.drop('Num_items', axis=1, inplace=True)\n",
    "    print(sorted_df.reset_index(drop=True))\n",
    "    \n",
    "main(minsup = 0.3, minconf = 0.8, minlift = 1.0, filename = 'supermarket.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
